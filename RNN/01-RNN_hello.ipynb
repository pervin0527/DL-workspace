{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = \"hihello\"\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 'h', 'i', 'l', 'o']\n",
      "{'e': 0, 'h': 1, 'i': 2, 'l': 3, 'o': 4}\n",
      "[1, 2, 1, 0, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "## one-hot encoding을 위한 label을 제작하기 위함.\n",
    "char_set = sorted(list(set(sample_data))) ## unique char 선별.\n",
    "char_dict = {c : i for i, c in enumerate(char_set)} ## label index 부여.\n",
    "sample_idx = [char_dict[c] for c in sample_data] ## sparse_categories list\n",
    "\n",
    "print(char_set)\n",
    "print(char_dict)\n",
    "print(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(char_set)\n",
    "hidden_dim = len(char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 1, 0, 3, 3]]\n",
      "[array([[0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 1., 0.]])]\n",
      "[[2, 1, 0, 3, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [sample_idx[:-1]] ## 마지막 문자 'o'를 제외한 나머지를 input으로 사용\n",
    "x_one_hot = [np.eye(input_dim)[x] for x in x_data] ## one_hot encoded vectors(stacked)\n",
    "\n",
    "y_data = [sample_idx[1:]] ## label은 반대로 첫번째 문자 'h'를 제외한 나머지를 사용하여 제대로 예측하는지 확인.\n",
    "\n",
    "print(x_data)\n",
    "print(x_one_hot)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 5]) torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(np.array(x_one_hot), dtype=torch.float32)\n",
    "Y = torch.tensor(y_data, dtype=torch.int64)\n",
    "h0 = torch.zeros(1, 1, hidden_dim) ## 맨 처음 사용될 h_{t-1}\n",
    "\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "criterion = nn.CrossEntropyLoss() ## Multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 5]) torch.Size([1, 1, 5])\n",
      "epoch0 | loss : 1.8366345167160034, prediction : hiehoh\n",
      "epoch1 | loss : 1.543753743171692, prediction : ioehii\n",
      "epoch2 | loss : 1.345700740814209, prediction : eoelio\n",
      "epoch3 | loss : 1.2051149606704712, prediction : ioello\n",
      "epoch4 | loss : 1.0974088907241821, prediction : ioello\n",
      "epoch5 | loss : 1.01070237159729, prediction : ioello\n",
      "epoch6 | loss : 0.9334042072296143, prediction : ioello\n",
      "epoch7 | loss : 0.8635385632514954, prediction : ioello\n",
      "epoch8 | loss : 0.7992921471595764, prediction : ioello\n",
      "epoch9 | loss : 0.7528714537620544, prediction : ioello\n",
      "epoch10 | loss : 0.7204034328460693, prediction : ioello\n",
      "epoch11 | loss : 0.6878079771995544, prediction : ioello\n",
      "epoch12 | loss : 0.6629229187965393, prediction : ihello\n",
      "epoch13 | loss : 0.6429349780082703, prediction : ihello\n",
      "epoch14 | loss : 0.6217709183692932, prediction : ihello\n",
      "epoch15 | loss : 0.6023480892181396, prediction : ihello\n",
      "epoch16 | loss : 0.5876160264015198, prediction : ihello\n",
      "epoch17 | loss : 0.5741453766822815, prediction : ihello\n",
      "epoch18 | loss : 0.5586437582969666, prediction : ihello\n",
      "epoch19 | loss : 0.5444390177726746, prediction : ihello\n",
      "epoch20 | loss : 0.53952556848526, prediction : ihello\n",
      "epoch21 | loss : 0.5395637154579163, prediction : ihello\n",
      "epoch22 | loss : 0.5321919322013855, prediction : ihello\n",
      "epoch23 | loss : 0.522338330745697, prediction : ihello\n",
      "epoch24 | loss : 0.5141208171844482, prediction : ihello\n",
      "epoch25 | loss : 0.5089143514633179, prediction : ihello\n",
      "epoch26 | loss : 0.5060160160064697, prediction : ihello\n",
      "epoch27 | loss : 0.5032392740249634, prediction : ihello\n",
      "epoch28 | loss : 0.5001039505004883, prediction : ihello\n",
      "epoch29 | loss : 0.4970909357070923, prediction : ihello\n",
      "epoch30 | loss : 0.4943970739841461, prediction : ihello\n",
      "epoch31 | loss : 0.4918891489505768, prediction : ihello\n",
      "epoch32 | loss : 0.4896365702152252, prediction : ihello\n",
      "epoch33 | loss : 0.48766979575157166, prediction : ihello\n",
      "epoch34 | loss : 0.48570045828819275, prediction : ihello\n",
      "epoch35 | loss : 0.48384854197502136, prediction : ihello\n",
      "epoch36 | loss : 0.48223569989204407, prediction : ihello\n",
      "epoch37 | loss : 0.4807232916355133, prediction : ihello\n",
      "epoch38 | loss : 0.47944173216819763, prediction : ihello\n",
      "epoch39 | loss : 0.47830697894096375, prediction : ihello\n",
      "epoch40 | loss : 0.47718366980552673, prediction : ihello\n",
      "epoch41 | loss : 0.4761572778224945, prediction : ihello\n",
      "epoch42 | loss : 0.4751488268375397, prediction : ihello\n",
      "epoch43 | loss : 0.4741438627243042, prediction : ihello\n",
      "epoch44 | loss : 0.4732499420642853, prediction : ihello\n",
      "epoch45 | loss : 0.472403883934021, prediction : ihello\n",
      "epoch46 | loss : 0.4716624319553375, prediction : ihello\n",
      "epoch47 | loss : 0.4710228443145752, prediction : ihello\n",
      "epoch48 | loss : 0.4704066216945648, prediction : ihello\n",
      "epoch49 | loss : 0.4698570668697357, prediction : ihello\n",
      "epoch50 | loss : 0.4692945182323456, prediction : ihello\n",
      "epoch51 | loss : 0.4687652587890625, prediction : ihello\n",
      "epoch52 | loss : 0.4682665765285492, prediction : ihello\n",
      "epoch53 | loss : 0.46780112385749817, prediction : ihello\n",
      "epoch54 | loss : 0.46739861369132996, prediction : ihello\n",
      "epoch55 | loss : 0.4670141041278839, prediction : ihello\n",
      "epoch56 | loss : 0.4666753113269806, prediction : ihello\n",
      "epoch57 | loss : 0.46633514761924744, prediction : ihello\n",
      "epoch58 | loss : 0.4660152494907379, prediction : ihello\n",
      "epoch59 | loss : 0.4656964838504791, prediction : ihello\n",
      "epoch60 | loss : 0.46539047360420227, prediction : ihello\n",
      "epoch61 | loss : 0.4651005268096924, prediction : ihello\n",
      "epoch62 | loss : 0.46482419967651367, prediction : ihello\n",
      "epoch63 | loss : 0.4645700454711914, prediction : ihello\n",
      "epoch64 | loss : 0.4643234312534332, prediction : ihello\n",
      "epoch65 | loss : 0.46409156918525696, prediction : ihello\n",
      "epoch66 | loss : 0.46385788917541504, prediction : ihello\n",
      "epoch67 | loss : 0.4636334180831909, prediction : ihello\n",
      "epoch68 | loss : 0.46340784430503845, prediction : ihello\n",
      "epoch69 | loss : 0.4631940424442291, prediction : ihello\n",
      "epoch70 | loss : 0.4629844129085541, prediction : ihello\n",
      "epoch71 | loss : 0.4627875089645386, prediction : ihello\n",
      "epoch72 | loss : 0.4625944197177887, prediction : ihello\n",
      "epoch73 | loss : 0.46240997314453125, prediction : ihello\n",
      "epoch74 | loss : 0.4622267484664917, prediction : ihello\n",
      "epoch75 | loss : 0.4620485305786133, prediction : ihello\n",
      "epoch76 | loss : 0.461871862411499, prediction : ihello\n",
      "epoch77 | loss : 0.46170029044151306, prediction : ihello\n",
      "epoch78 | loss : 0.4615325927734375, prediction : ihello\n",
      "epoch79 | loss : 0.4613700807094574, prediction : ihello\n",
      "epoch80 | loss : 0.46121248602867126, prediction : ihello\n",
      "epoch81 | loss : 0.4610579013824463, prediction : ihello\n",
      "epoch82 | loss : 0.46090731024742126, prediction : ihello\n",
      "epoch83 | loss : 0.4607577621936798, prediction : ihello\n",
      "epoch84 | loss : 0.46061190962791443, prediction : ihello\n",
      "epoch85 | loss : 0.46046721935272217, prediction : ihello\n",
      "epoch86 | loss : 0.4603266417980194, prediction : ihello\n",
      "epoch87 | loss : 0.46018826961517334, prediction : ihello\n",
      "epoch88 | loss : 0.46005335450172424, prediction : ihello\n",
      "epoch89 | loss : 0.45992088317871094, prediction : ihello\n",
      "epoch90 | loss : 0.45979049801826477, prediction : ihello\n",
      "epoch91 | loss : 0.459662526845932, prediction : ihello\n",
      "epoch92 | loss : 0.45953568816185, prediction : ihello\n",
      "epoch93 | loss : 0.45941147208213806, prediction : ihello\n",
      "epoch94 | loss : 0.45928871631622314, prediction : ihello\n",
      "epoch95 | loss : 0.45916831493377686, prediction : ihello\n",
      "epoch96 | loss : 0.4590500295162201, prediction : ihello\n",
      "epoch97 | loss : 0.45893344283103943, prediction : ihello\n",
      "epoch98 | loss : 0.4588189125061035, prediction : ihello\n",
      "epoch99 | loss : 0.4587056338787079, prediction : ihello\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs, status = model(X)\n",
    "    \n",
    "    if i == 0:\n",
    "        print(outputs.shape, status.shape)\n",
    "    \n",
    "    loss = criterion(outputs.view(-1, input_dim), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.data.numpy().argmax(axis=2)\n",
    "    result_str = ''.join([char_set[c] for c in np.squeeze(result)])\n",
    "\n",
    "    print(f\"epoch{i} | loss : {loss.item()}, prediction : {result_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
