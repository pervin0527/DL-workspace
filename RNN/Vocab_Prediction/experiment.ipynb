{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchtext import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from utils import data_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(data, fname):\n",
    "    with open(fname, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def load_pkl(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi30k:\n",
    "    UNK, UNK_IDX = \"<unk>\", 0\n",
    "    PAD, PAD_IDX = \"<pad>\", 1\n",
    "    SOS, SOS_IDX = \"<sos>\", 2\n",
    "    EOS, EOS_IDX = \"<eos>\", 3\n",
    "    SPECIALS = {UNK : UNK_IDX, PAD : PAD_IDX, SOS : SOS_IDX, EOS : EOS_IDX}\n",
    "\n",
    "    def __init__(self, data_dir, target_language, max_seq_len, min_freq):\n",
    "        self.data_dir = f\"{data_dir}/Multi30k\"\n",
    "        self.cache_dir = f\"{self.data_dir}/caches\"\n",
    "\n",
    "        if not os.path.isdir(self.data_dir):\n",
    "            data_download(self.data_dir)\n",
    "\n",
    "        self.target_language = target_language\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.min_freq = min_freq\n",
    "\n",
    "        self.target_tokenizer = self.build_tokenizer(self.target_language)\n",
    "\n",
    "        self.train, self.valid, self.test = None, None, None\n",
    "        self.build_dataset()\n",
    "\n",
    "        self.vocab = None\n",
    "        self.build_vocab()\n",
    "\n",
    "        self.vocab_transform = None\n",
    "        self.build_transform()\n",
    "\n",
    "\n",
    "    def build_tokenizer(self, language):\n",
    "        spacy_lang_dict = {'en': \"en_core_web_sm\", 'de': \"de_core_news_sm\"}\n",
    "        assert language in spacy_lang_dict.keys()\n",
    "\n",
    "        return get_tokenizer(\"spacy\", spacy_lang_dict[language])\n",
    "\n",
    "\n",
    "    def build_dataset(self):\n",
    "        if not os.path.isdir(self.cache_dir):\n",
    "            os.makedirs(self.cache_dir)\n",
    "\n",
    "        train_pkl = f\"{self.cache_dir}/train.pkl\"\n",
    "        if os.path.exists(train_pkl):\n",
    "            self.train = load_pkl(train_pkl)\n",
    "\n",
    "        else:\n",
    "            with open(f\"{self.data_dir}/train.en\") as f:\n",
    "                self.train = [text.rstrip() for text in f]\n",
    "        \n",
    "            save_pkl(self.train, train_pkl)\n",
    "\n",
    "        val_pkl = f\"{self.cache_dir}/val.pkl\"\n",
    "        if os.path.exists(val_pkl):\n",
    "            self.val = load_pkl(val_pkl)\n",
    "            \n",
    "        else:\n",
    "            with open(f\"{self.data_dir}/val.en\") as f:\n",
    "                self.val = [text.rstrip() for text in f]\n",
    "        \n",
    "            save_pkl(self.val, val_pkl)\n",
    "\n",
    "        test_pkl = f\"{self.cache_dir}/test.pkl\"\n",
    "        if os.path.exists(test_pkl):\n",
    "            self.test = load_pkl(test_pkl)\n",
    "            \n",
    "        else:\n",
    "            with open(f\"{self.data_dir}/test.en\") as f:\n",
    "                self.test = [text.rstrip() for text in f]\n",
    "        \n",
    "            save_pkl(self.test, test_pkl)\n",
    "\n",
    "\n",
    "    def build_vocab(self):\n",
    "        assert self.train is not None\n",
    "\n",
    "        def yield_tokens():\n",
    "            for text in self.train:\n",
    "                yield [str(token) for token in self.target_tokenizer(text)]\n",
    "\n",
    "        vocab_file = f\"{self.cache_dir}/vocab_{self.target_language}.pkl\"\n",
    "        if os.path.exists(vocab_file):\n",
    "            vocab = load_pkl(vocab_file)\n",
    "        else:\n",
    "            vocab = build_vocab_from_iterator(yield_tokens(), min_freq=self.min_freq, specials=self.SPECIALS.keys())\n",
    "            vocab.set_default_index(self.UNK_IDX)\n",
    "            save_pkl(vocab, vocab_file)\n",
    "\n",
    "        self.vocab = vocab\n",
    "\n",
    "\n",
    "    def build_transform(self):\n",
    "        def get_transform(self, vocab):\n",
    "            return transforms.Sequential(transforms.VocabTransform(vocab),\n",
    "                                         transforms.Truncate(self.max_seq_len),\n",
    "                                        #  transforms.AddToken(token=self.SOS_IDX, begin=True),\n",
    "                                        #  transforms.AddToken(token=self.EOS_IDX, begin=False),\n",
    "                                         transforms.ToTensor(padding_value=self.PAD_IDX))\n",
    "\n",
    "        self.vocab_transform = get_transform(self, self.vocab)\n",
    "\n",
    "    def one_hot_encoding(self, tensor):\n",
    "        batch_size, sequence_length = tensor.size()\n",
    "        one_hot_tensor = torch.zeros(batch_size, sequence_length, len(self.vocab), dtype=torch.int64)\n",
    "        for i in range(batch_size):\n",
    "            for j in range(sequence_length):\n",
    "                one_hot_tensor[i, j, tensor[i, j]] = 1\n",
    "\n",
    "        return one_hot_tensor        \n",
    "\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        trg = [self.target_tokenizer(data) for data in batch]\n",
    "        # trg_transform = self.vocab_transform(trg)\n",
    "        \n",
    "        x_data = [t[:-1] for t in trg]\n",
    "        y_data = [t[1:] for t in trg]\n",
    "\n",
    "        X = self.vocab_transform(x_data)\n",
    "        Y = self.vocab_transform(y_data)\n",
    "\n",
    "        X = self.one_hot_encoding(X)\n",
    "        Y = self.one_hot_encoding(Y)\n",
    "        \n",
    "        return batch, X, Y\n",
    "\n",
    "\n",
    "    def get_iter(self, **kwargs):\n",
    "        if self.vocab_transform is None:\n",
    "            self.build_transform()\n",
    "\n",
    "        train_iter = DataLoader(self.train, collate_fn=self.collate_fn, **kwargs)\n",
    "        valid_iter = DataLoader(self.valid, collate_fn=self.collate_fn, **kwargs)\n",
    "        test_iter = DataLoader(self.test, collate_fn=self.collate_fn, **kwargs)\n",
    "\n",
    "        return train_iter, valid_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "MAX_SEQ_LEN = 256\n",
    "MIN_FREQ = 1\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "NUM_WORKERS = min([os.cpu_count(), BATCH_SIZE if BATCH_SIZE > 1 else 0, 8])\n",
    "\n",
    "DATASET = Multi30k(\"/home/pervinco/Datasets/test\", \"en\", MAX_SEQ_LEN, MIN_FREQ)\n",
    "train_iter, valid_iter, test_iter = DATASET.get_iter(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 14, 6191])\n",
      "torch.Size([4, 14, 6191])\n"
     ]
    }
   ],
   "source": [
    "for idx, (sentence, X, Y) in enumerate(train_iter):\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6191 6191\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(DATASET.vocab)\n",
    "OUTPUT_DIM = len(DATASET.vocab)\n",
    "print(INPUT_DIM, OUTPUT_DIM)\n",
    "\n",
    "EMBED_DIM = 256\n",
    "HIDDEN_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNLanguageModel(\n",
      "  (embedding): Embedding(6191, 256, padding_idx=1)\n",
      "  (rnn): RNN(256, 512)\n",
      "  (fc): Linear(in_features=512, out_features=6191, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNNLanguageModel(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, output_dim, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src) ## src shape: [src_len, batch_size]\n",
    "        output, _ = self.rnn(embedded) ## embedded shape: [src_len, batch_size, emb_dim]\n",
    "        \n",
    "        return self.fc(output) ## output shape: [src_len, batch_size, hidden_dim]\n",
    "\n",
    "\n",
    "model = RNNLanguageModel(INPUT_DIM, EMBED_DIM, HIDDEN_DIM, OUTPUT_DIM, DATASET.PAD_IDX)\n",
    "model = model.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=DATASET.PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for idx, (_, X, Y) in enumerate(iterator):\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        print(X.shape, Y.shape)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "\n",
    "        print(output.shape)\n",
    "        break\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    for idx, (sentence, X, Y) in enumerate(iterator):\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        output = model(X)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 14, 6191]) torch.Size([4, 14, 6191])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "RNN: Expected input to be 2-D or 3-D but received 4-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_iter, optimizer, criterion)\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(train_loss)\n",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape, Y\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mRNNLanguageModel.forward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, src):\n\u001b[1;32m     10\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(src) \u001b[39m## src shape: [src_len, batch_size]\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     output, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(embedded) \u001b[39m## embedded shape: [src_len, batch_size, emb_dim]\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:476\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m     batch_sizes \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m     \u001b[39massert\u001b[39;00m (\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRNN: Expected input to be 2-D or 3-D but received \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m     is_batched \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m    478\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: RNN: Expected input to be 2-D or 3-D but received 4-D tensor"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train(model, train_iter, optimizer, criterion)\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNNPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNPredictor, self).__init__()\n",
    "\n",
    "        # input_size: vocab_size\n",
    "        # hidden_size: RNN의 hidden layer의 크기\n",
    "        # output_size: 예측된 단어의 확률 분포를 위한 크기 (vocab_size와 동일)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # RNN layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to get the next word probabilities\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # Passing in the input and hidden state into the RNN\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "        \n",
    "        # Reshaping the RNN output to fit into the fully connected layer\n",
    "        r_out = r_out.contiguous().view(-1, self.hidden_size)\n",
    "        \n",
    "        # Getting the next word probabilities\n",
    "        output = self.fc(r_out)\n",
    "        \n",
    "        # Reshaping to batch_size, seq_len, vocab_size\n",
    "        output = output.view(x.size(0), x.size(1), -1)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Initializes hidden state\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # 입력과 hidden state를 동시에 처리할 수 있는 가중치\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        batch_size, seq_len, _ = input_seq.size()\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            input_t = input_seq[:, t, :]  # 현재 시점의 입력\n",
    "            combined = torch.cat((input_t, hidden), dim=1)  # 입력과 hidden state를 결합\n",
    "            hidden = torch.tanh(self.i2h(combined))\n",
    "            output = self.h2o(hidden)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return torch.stack(outputs, dim=1), hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # 입력과 hidden state를 동시에 처리할 수 있는 가중치\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        batch_size, seq_len, _ = input_seq.size()\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            input_t = input_seq[:, t, :]  # 현재 시점의 입력\n",
    "            combined = torch.cat((input_t, hidden), dim=1)  # 입력과 hidden state를 결합\n",
    "            hidden = torch.tanh(self.i2h(combined))\n",
    "            output = self.h2o(hidden)\n",
    "            outputs.append(output)\n",
    "\n",
    "        return torch.stack(outputs, dim=1), hidden\n",
    "\n",
    "    def init_hidden_state(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
